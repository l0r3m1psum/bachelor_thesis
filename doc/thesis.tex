% !TeX encoding = UTF-8
% !TeX program = pdflatex
% !TeX spellcheck = it_IT
\let\oldcases\cases % to fool amsmath
\documentclass[Lau]{sapthesis} % LaM for a Laurea Magistrale

\usepackage{microtype}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}

\hypersetup{
	pdftitle={Multi-thread simulation of a large scale dynamical system},
	pdfauthor={Diego Bellani},
	pdfsubject={Bachelor thesis},
	pdfkeywords={bachelor,thesis,programming},
	pdfproducer={LaTeX},
	pdfcreator={pdfLaTeX},
	pdfborder={0 0 0},
	pageanchor=false
}

\title{Multi-thread simulation of a large scale dynamical system}
\author{Diego Bellani}
\IDnumber{1838645}
\course{Informatica}
\courseorganizer{Facoltà di Ingegneria dell'Informazione Informatica e Statistica}
\AcademicYear{2020/2021}
\copyyear{2021}
\advisor{Prof. Tronci}
\authoremail{bellanidiego@gmail.com}

\newtheorem{requirement}{Requirement}
\newcommand{\e}{\epsilon}
\newlength{\rulewidth}\setlength{\rulewidth}{0.4pt}
\newcommand{\myrule}{\noindent\rule{\textwidth}{\rulewidth}}
\def\cases#1{\oldcases{#1}} % always to fool amsmath

\let\oldsection\section
\let\oldsubsection\subsection

\def\subsubsection{\oldsubsection}
\def\subsection{\oldsection}
\def\section{\chapter}

% ERRORI TROVATI:
% * la probabilità deterministica (si erano scordati di dirci quali termini
%   perturbare)
% * divisioni per zero
% * mancanza di unità di misura
% * funzioni senza definizioni e mal poste (gamma può dare al più tre output per
%   amor del vero)
% * non è stato specificato cosa fare sulle condizioni del bordo
% * la halting condition è stata detta solo alla fine, all'inizio non ce n'era
%   nessuna

\begin{document}

\frontmatter
\maketitle

\begin{abstract}
In this internship report I describe how a software for large scale, high
performance, forest fire simulation was developed, starting from a model given
by a third party and ending in a functioning implementation. The technology used
are described together with the various problems faced during the development
process. Finally some possible improvements and future developments are
described at the end.
\end{abstract}

\tableofcontents
\listoffigures
\listoftables

\mainmatter

\section{Introduction}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Firefighting in forests is a complex activity due to the limited availability of
means and resources. Therefore the intervention strategy have to consider the
possible evolution of the fire to make the best use of what is available.

The possible evolution of a fire can be characterized with a mathematical model
and predicted with a faster-then-real-time simulation of said model. Given
this, actions can be taken ahead of time to minimize the damage caused by the
fire and maximize the fire extinction speed.

\subsection{Context}

This internship is part of a project called ``Satellite Driven Fire Simulator'',
financed by the region of Lazio, to aid firefighters fight put out forest fires.

This project is divided in four parts:

\begin{enumerate}
\item development of a mathematical model (done by Paola Russo of the Tor
Vergata university \cite{mod});
\item \label{enum:my_work} development of a software to run the mathematical
model (done by me);
\item \label{enum:interaction} development of a user interface for data input
to the simulator and showing the results in a human readable fashion;
\item \label{enum:data} gathering the data from the field, this includes
geographic data from satellites \cite{cop} and meteorologic data from on field
sensors.
\end{enumerate}

\subsection{Motivations}

To make predictions possible a software has to be developed that can show the
evolution of forest fires ahead of time.

The original implementation was made in Microsoft
Excel\textsuperscript{\textregistered}, which is fine for prototyping but not
suitable for fast large scale simulations. Therefore a better implementation was
needed both for speed and user friendliness.

For this purpose an Intel server running a Linux based operating system was
provided.

The usual tool we used for implementation of mathematical models, Modelica, did
not made the cut because of its limitation regarding dynamically sized arrays
and the exponential time taken by the optimization algorithm at the increasing
of the size of the simulation grid.

Libraries exists to develop cellular automata models \cite{calib2}, but with
generality comes a lost in performance.

This said Modelica was still a valuable tool for prototyping a small version of
the model before its real implementation.

\subsection{Contributions}

I have implemented from scratch the simulator dividing it in two parts a data
integration one and a model execution one. Given that other parts of the project
have still to be implemented the data integration part of my software can be
used to make this other parts communicate between each other.

Regarding the model that was used to implement the software, some corrections
have been done to it, by me and my advisor (i.e. I have noticed the problems and
my advisor promptly reported them or corrected them on his own).

\subsection{Related Work}

Given that the model was provided to my by an external source, and therefore not
developed by me, I am not in the position to cite work related to that.

On the implementation side of things no inspiration was taken by other
implementations of fire simulator, so the same thing as before applies

\subsection{Outline}

This report is divided in 5 main sections. The first reviews the necessary
background information necessary to understand the work done. The second one
talks about the mathematical model and than the methods used to implement it, in
a mostly theoretical/high level way. The third talks about the actual
implementation of the software. The fourth talks about the experimental activity
done with the working program and the fifth and final section talks about what
could be done better in the current implementation and in eventual future works.

\section{Background}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The work done in this internship revolves around three topics in particular:
cellular automata, the relational data model \cite{codd} and multithreaded
programming.

For the implementation side 4 main technologies have been used: the C
programming language for the implementation of the model, the SQL language for
interfacing with the database, the POSIX shell to integrate the database with
the implementation of the model and the OpenMP compiler extensions for the
parallelization of the algorithm.

The next sub-sections are dedicated to introducing all those previously cited
topics and technologies.

\subsection{Cellular Automata}

A cellular automata is a discrete model of computation based on a grid of cells
each with a finite number of states. Each cell has a neighborhood associated
with it, and it it used together with some rules to calculate the next
generation.

A particularly famous cellular automata configuration is the one created by
John~H.~Conway called ``Game of Life'' \cite{gol} it is played on a rectangular
grid (or a thorus), the neighborhood of each cell are the 8 around it (also
known as the Moore neighborhood) and each cell has two state alive or dead.
There are three rules, one that determines the survival of a cell, on the death
and one the birth.

Even such a simple cellular automata has many interesting features, one of which
is being Turing complete \cite{win}.

Cellular automata have found applications in various scientific fields
\cite{cellularbio}. Even in the modeling of fire evolution as this project
shows.

\subsection{Relational Data Model}

The relational data model is a data model proposed by Edgar~F.~Codd for database
management systems. As the name implies it is based on mathematical relations. A
database is a collection of relation of tuples each of which is made of atomical
values, this can be viewed as a set of tables. In the years what `atomical'
values are is changed \cite{ordb}. In the modern days an atomical value can be
an array, a tree structure or ever a tuple (record or struct) itself. This while
being counter intuitive is done for performance and expressiveness reasons.

In the schema made for this project array ad tuples where used as atomic values
in fact.

\subsection{Multithreading}

Multithreading is a computer architecture term that indicates that a single CPU
has multiples `cores' on it, each one with its own computational capability.
This can be taken advantage by programs, because the work can be divided across
the cores and executed in parallel. This can lead to speed ups in the execution
time linear to the amount of cores on the CPU, but often is not that easy to
archive this improvements due to synchronization problems.

\subsection{C}

C is a system programming language developed as a successor to the B programming
language at Bell Labs by Dennis~M.~Ritchie that has become the primary
implementation language for UNIX-like operating systems kernels and utilities.

The language is standardized by ISO and the version used in this project is
called C11, except for the standard library and the POSIX system interfaces no
other libraries were used.

\subsubsection{OpenMP}

OpenMP stands for Open Multi-Processing, it comprises a series of compiler
extensions, environment variables and library functions, for the C, C++ and
Fortran programming languages, that enables multithreaded programming with
minimal source code modification.

\subsection{SQL}

SQL stands for Structured Query Language, and it is a domain specific language,
for querying, manipulating and defining relational data. It is the de facto
standard language used for interfacing with databases based on the relational
data model.

The version used in this project is called SQL\raisebox{0.04cm}{:}98.

\subsection{Shell}

The Bourne Shell \texttt{sh(1)} is a programming language used for interfacing
with UNIX-like operating system, first developed by Stephen~Bourne at Bell Labs
and then standardized by POSIX.

Other shells exists but this is the only standardized one and many of the other
ones have this as a subset, so it is easy to found in a system.

\subsubsection{POSIX}

As said in the previous section the shell used is the one standardized by POSIX.
POSIX is a family of standards defined by the IEEE (technically called IEEE
1003) for portability among operating systems, in fact it stands for ``Portable
Operating System Interface''. It defines both user programs (like the shell and
its utilities) and operating system API (system calls).

While not necessary, for performance reason some POSIX API have been used in the
C code too. This decreased its portability (which is guaranteed among all
operating systems if the standard library is used) to only POSIX systems, but
this kind of system was the only system the simulator was meant to run on.

\section{Methods}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The majority of time in this project was spent on refining the mathematical
model given to us. Not only by stating it in a precise way the math in the model
but also in deriving from it a set of implementable requirements, that were not
very clear in the beginning, even though in retrospect seems obvious.

After this activity was terminated the creation of the database schema and the
implementation of the model was relatively straight forward.

\subsection{Model \& Data}

I have divided the model discussion in two parts a short introduction to the
data used, and than a longer discussion about the math used where the data used,
introduced in precedence, is refined.

\subsubsection{Data}\label{sec:data}

Now let's briefly talk about the data that the simulation will have at its
disposal, successively they will be described in a more precise way. The
simulation has two kinds of data at his disposal geographical, from satellite
\cite{cop}, and meteorological from meteo station in place. The zone is divided
in squares and each square has uniform data.

The geographical datum are: altimetry, forest kind, urbanization level, eventual
water presence and the ``carta natura'', the last one is currently unused.

The meteorological data are just wind speed and direction.

\subsubsection{Model}

To describe the evolution of forest fire the model is based on three simple
observations

\begin{enumerate}
\item a fire burns until there is fuel,
\item a fire consume fuel,
\item a fire can move to a neighboring area.
\end{enumerate}

After having divided a rectangular area in $L^* \times W^*$ squared cells, we
understand that of each cell, in row $i$ and column $j$, of the forest we care
about just two characteristics: the fuel quantity it it at a certain point in
time $B_{ij}(t)$ and the presence or not of a fire in said cell at a certain
point in time $N_{ij}(t)$, $N$ can assume only two values 0 for no fire and 1
for fire, we will call function like this \emph{fire indicator functions}. Those
two functions will represent the \emph{state} of the cell at any point in time.

Next to describe the concept of movement of the fire to neighboring cells a
cellular automata approach was used.

But first we have to consider that a fire could have multiple triggering points
across time, for example when we consider arson, for this cases a simple notion
of initial state is not sufficient, we need a way to talk about the exogenous
input of the system, let's call it $u_{ij}(t)$, and it is a fire indicator
function.

We can formalize everything that we have said until now with those equations

\begin{eqnarray}
N_{ij}(0) &=& u_{ij}(0)\textrm{,}\\
B_{ij}(0) &=& \gamma_{ij}\textrm{,}\\
N_{ij}(t+1) &=& \cases{\max(V_{ij}(t), u_{ij}(t)), &if $\underbrace{B_{ij}(t)}_\textrm{fuel} > 0$;\cr
                       0, &else.}\\
B_{ij}(t+1) &=& \cases{\max(0, B_{ij}(t)-\beta_{ij}\tau), &if $\underbrace{N_{ij}(t)}_\textrm{fire} > 0$;\cr
                       B_{ij}(t), &else.}
\end{eqnarray}

Where $\gamma_{ij}$is the initial fuel quantity in a cell, $V_{ij}(t)$ is the
possibility that the fire moves in the current cell from a neighboring one
(figure \ref{fig:automata}), $\beta_{ij}$ is the fuel consumption speed in a
particular cell and $\tau$ is the time step.

\begin{figure}
\centering
\setlength{\unitlength}{0.7cm}
\begin{picture}(6,6)
	\newlength{\piccenter}
	\setlength{\piccenter}{3\unitlength}
	% Grid
	\thicklines
	\multiput(0,0)(2,0){4}{\line(0,1){6}} % columns
	\multiput(0,0)(0,2){4}{\line(1,0){6}} % rows

	% Arrays
	\thinlines
	\put(\piccenter,\piccenter){\vector(1,0){2}}
	\put(\piccenter,\piccenter){\vector(0,1){2}}
	\put(\piccenter,\piccenter){\vector(-1,0){2}}
	\put(\piccenter,\piccenter){\vector(0,-1){2}}
	\put(\piccenter,\piccenter){\vector(1,1){2}}
	\put(\piccenter,\piccenter){\vector(-1,1){2}}
	\put(\piccenter,\piccenter){\vector(1,-1){2}}
	\put(\piccenter,\piccenter){\vector(-1,-1){2}}

	% Black square
	\newlength{\side}
	\setlength{\side}{0.8\unitlength}
	\linethickness{\side}
	\newlength{\ypos}
	\setlength{\ypos}{\piccenter}
	\addtolength{\ypos}{-0.5\side}
	\put(\piccenter,\ypos){\line(0,0){\side}}
\end{picture}
\caption{Neighborhood of a cell.}
\label{fig:automata}
\end{figure}

Obviously the heart of this model is the function $V_{ij}(t)$, another fire
indicator functions that it is defined in the following way

\begin{eqnarray}
            V_{ij}(t) &=& \max\{\,Q_{ij}(\e_1, \e_2, t) \mid (\e_1, \e_2) \in \Gamma\,\}\textrm{,}\\
               \Gamma &=& \{\,(x, y) \mid x, y \in \{-1, 0, 1\}\,\}\textrm{,}\\
Q_{ij}(\e_1, \e_2, t) &=& \cases{1, &if $p_{ij}(\e_1, \e_2, t) N_{i+\e_1j+\e_2}(t) > \theta$;\cr
                                 0, &else.}\label{eq:probtest}
\end{eqnarray}

Where $p_{ij}(\e_1, \e_2, t)$ is the probability that the fire moves from the
neighbor cell $(i+\e_1, j+\e_2)$ to the current cell $(i,j)$, $\theta$ is the
fire propagation threshold.

\myrule

Let's suspend, for now, our discussion about the model to better describe the
data at our disposal, introduced in section \ref{sec:data}.

The satellite puts at our disposal a series of data, described in the table
\ref{tab:geo}, the underlined ones are currently not used, the meaning of the
values is described in the appendix \ref{sec:desc}. However those data cannot be
used as is in the model but have to be ``refined'' with the following
mathematical correspondences.

\begin{table}
\centering
\begin{tabular}{|c|l|c|}
	\hline
	\textbf{Symbol} & \textbf{Name} & \textbf{Interval}\\
	\hline
	$G$ & Forests & 0,1,2,255\\
	$U$ & Urbanization & 0,\ldots,100,255\\
	$W1$ & Water1 & 0,\ldots,4,253,255\\
	$W2$ & \underline{Water2} & 0,1\\
	$P$ & Altimetry & 0,\ldots,4380\\
	$CN$ & \underline{Nature Card} & 1,\ldots,90\\
	\hline
\end{tabular}
\caption{Geographical data for the single cell.}
\label{tab:geo}
\end{table}

\begin{equation}\label{eq:height}
H_{ij} = \cases{1 + G_{ij}, &if $0 \leq G_{ij} \leq 2$;\cr
                  0, &if $G_{ij} = 255$.}
\end{equation}

is the medium height of the vegetation in a cell,

\begin{equation}\label{eq:inhabitants}
A_{ij} = \cases{U_{ij}/100, &if $0 \leq U_{ij} \leq 100$;\cr
                0, &if $U_{ij} = 255$.}
\end{equation}

is the percentage of the cell that is inhabited,

\begin{equation}\label{eq:water}
W_{ij} = \cases{0, &if $W1_{ij} = 0$;\cr
                1, &if $W1_{ij} = 1$;\cr
                0.75, &if $W1_{ij} = 2$;\cr
                0.75, &if $W1_{ij} = 3$;\cr
                0.5, &if $W1_{ij} = 4$;\cr
                1, &if $W1_{ij} = 253$;\cr
                1, &if $W1_{ij} = 255$.}
\end{equation}

is the percentage of water present. Those last three values are needed to
calculate two values

\begin{equation}
S_{ij} = H_{ij} \cdot (1-A_{ij}) \cdot (1-W_{ij})\textrm{,}\\
\end{equation}

that is the level of inflammability of the cell, notice that $A_{ij}$ decreases
it because inhabited zones are usually cemented, and

\begin{equation} % NOTE: 4000 is the average wood density
\gamma_{ij} = 4000(H_{ij}-A_{ij})\textrm{.}
\end{equation}

The average height of a cell $P_{ij}$, is the only value left unchanged.

Now that we have finished to talk about the data used from the satellite, we can
talk about how the meteorological data is used in the simulation i.e. the speed
and direction of the wind

\begin{eqnarray}
\mathcal{F}_{ij} &=& F_{ij} + F_{ij}0.2r_1\\
\mathcal{D}_{ij} &=& D_{ij} + D_{ij}0.2r_2
\end{eqnarray}

Where $r_1$ and $r_2$ are two random numbers drawn from a normal distribution
centered in 0 between 1 and -1.

Finally we can calculate

\begin{equation}
\beta_{ij} = 60(1+\mathcal{F}_{ij}/10)\textrm{,}
\end{equation}

Of the values not mentioned in precedence in the model just $S_{ij}$, $P_{ij}$,
$\mathcal{F}_{ij}$ and $\mathcal{D}_{ij}$ will be used.

\myrule

Now that we know which data we have at our disposal, we can finally define
$p_{ij}(\e_1, \e_2, t)$ from function \ref{eq:probtest}.

\begin{equation}\label{eq:prob}
p_{ij}(\e_1, \e_2, t+1) = k_0 S_{ij} C_{i+\e_1j+\e_2}(t) d(\e_1, \e_2) f_w f_P\textrm{,}
\end{equation}

where $k_0$ is an optimization parameter and

\begin{equation}\label{eq:combust}
C_{i+\e_1j+\e_2}(t+1) = \exp\left(-\frac{B_{i+\e_1j+\e_2}(t) - \gamma_{i+\e_1j+\e_2}^2/4}{\Delta}\right)\textrm{,}
\end{equation}

is the combustion state of the cell. The  value that $C$ can assume has the form
of a gaussian curve so that the maximum value is reached when half of the fuel
is burned.

\begin{equation}\label{eq:disom}
d(\e_1, \e_2) = \left(1-\frac{1}{2}|\e_1\e_2|\right)\textrm{,}
\end{equation}

is the dishomogeneity factor at the border of cells. It can assume only two
values 1 and $1/2$, the first is assumed when the considered cell is above,
below, to the left or to the right of the current cell the second one, instead,
when the considered cell is on a diagonal. This is done to take into account the
fact that the fire transmits less to diagonal neighbor, as shown in figure
\ref{fig:disom}.

\begin{figure} % TODO: fix nummber positioning
\centering
\setlength{\unitlength}{0.7cm}
\begin{picture}(6,6)
	\setlength{\piccenter}{3\unitlength}
	% Grid
	\thicklines
	\multiput(0,0)(2,0){4}{\line(0,1){6}} % columns
	\multiput(0,0)(0,2){4}{\line(1,0){6}} % rows

	\put(1,5){1/2}
	\put(3,5){1}
	\put(5,5){1/2}
	\put(1,3){1}
	\put(5,3){1}
	\put(1,1){1/2}
	\put(3,1){1}
	\put(5,1){1/2}

	% Black square
	\setlength{\side}{0.8\unitlength}
	\linethickness{\side}
	\setlength{\ypos}{\piccenter}
	\addtolength{\ypos}{-0.5\side}
	\put(\piccenter,\ypos){\line(0,0){\side}}
\end{picture}
\caption{Disomogeneity at the border of the cell.}
\label{fig:disom}
\end{figure}

\begin{equation}\label{eq:wind}
f_w = \exp\left(k_1 \mathcal{F}_{i+\e_1j+\e_2}\frac{\begin{array}{c}\e_1\cos(\mathcal{D}_{i+\e_1j+\e_2})\\
      +\\\e_2\sin(\mathcal{D}_{i+\e_1j+\e_2})\end{array}}{\sqrt{\e_1^2 + \e_2^2}}\right)
\end{equation}

is the wind contribution, where $k_1$ is its optimization parameter, at last

\begin{equation}\label{eq:slope}
f_P = \exp\left(k_2\arctan\left(\frac{P_{ij}-P_{i+\e_1j+\e_2}}{L}\right)\right)
\end{equation}

is the contribution given from the slope between two cells and $k_2$ is its
optimization parameter.

To conclude the description of the model we state the halting condition: the
simulation halts iff no fire has been transmitter to a neighboring cell in an
entire simulation step.

All global parameters of the model and the ones of the single cells have been
grouped in tables \ref{tab:globals} and \ref{tab:params}.

\begin{table}
\centering
\begin{tabular}{|c|l|c|}
	\hline
	\textbf{Symbol} & \textbf{Name} & \textbf{Unit of measure}\\
	\hline
	$\tau$ & time step & seconds\\
	$L$ & side length of a cell & meters\\
	$L^*$ & length of the simulated area & meters\textsuperscript{2}\\
	$W^*$ & width of the simulated area & meters\textsuperscript{2}\\
	$\Delta$ & height of the normal distribution & adimensional\\
	$\theta$ & propagation probability & adimensional\\
	$k_0$ & threshold optimization & adimensional\\
	$k_1$ & wind optimization & adimensional\\
	$k_2$ & slope optimization & adimensional\\
	\hline
\end{tabular}
\caption{Parameters valid for each cell.}
\label{tab:globals}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|l|c|}
	\hline
	\textbf{Symbol} & \textbf{Name} & \textbf{Unit of measure}\\
	\hline
	$H$ & medium height of the vegetation & meters\\
	$A$ & urbanization percentage & adimensional\\
	$W$ & percentage of water presence & adimensional\\
	$\beta$ & combustion speed & kilograms/second\\
	$\gamma$ & fuel quantity & kilograms\\
	$S$ & inflammability percentage & adimensional\\
	$P$ & medium height & meters\\
	$\mathcal{D}$ & wind direction & radiants\\
	$\mathcal{F}$ & wind speed & meters/second\\
	\hline
\end{tabular}
\caption{Parameters for single cells.}
\label{tab:params}
\end{table}

\subsection{Database Schema}\label{sec:schema}

The ER diagram for the database schema is shown in figure \ref{fig:er}. It is a
simple diagram where attributes have been omitted but are reported here.

\begin{figure}
\setlength{\unitlength}{1cm}
\setlength{\fboxsep}{6pt}
\newlength{\rhombuslength}
\setlength{\rhombuslength}{2\unitlength}
\newlength{\rhombuswidth}
\setlength{\rhombuswidth}{2\rhombuslength}
\newlength{\cardinalitydistance}
\setlength{\cardinalitydistance}{2.7\unitlength}

\centering
\begin{picture}(4,10)

\newsavebox{\rhombus}
\savebox{\rhombus}(\rhombuswidth,2)[bl]{
	\put(0,0){\line(2,1){\rhombuslength}}
	\put(0,0){\line(2,-1){\rhombuslength}}
	\put(\rhombuslength,1){\line(2,-1){\rhombuslength}}
	\put(\rhombuslength,-1){\line(2,1){\rhombuslength}}
}

\put(1.4,9){\fbox{Map}}
\put(\rhombuslength,8.7){\line(0,-1){0.6}}
\put(0,6.1){\usebox{\rhombus}}
\put(0.7,7){simulationResult}
\put(\rhombuslength,6.1){\line(0,-1){0.6}}
\put(1,5){\fbox{Simulation}}
\put(\rhombuslength,4.8){\line(0,-1){0.7}}
\put(0,2.1){\usebox{\rhombus}}
\put(0.9,3){mapSimulation}
\put(\rhombuslength,2.1){\line(0,-1){0.6}}
\put(1.2,1){\fbox{Result}}

\put(\cardinalitydistance,8){(0,N)}
\put(\cardinalitydistance,6){(1,1)}
\put(\cardinalitydistance,4){(0,N)}
\put(\cardinalitydistance,2){(1,1)}

\end{picture}
\caption{ER diagram}
\label{fig:er}
\end{figure}

\begin{itemize}
\item Map(\underline{id}, name, unit, rect, data)
\item Simulation(\underline{id}, name, rect, map, horizon, ``snapshot freq'',
seed, Delta, tau, theta, k0, k1, k2, L, started)
\item Result(\underline{sim}, \underline{seq}, data)
\end{itemize}

The `data' attribute in Map is an array of tuples containing all the data,
meteorological and geographical, of the single cells discussed before, the
`data' attribute in Result is an array tuples containing the state of the cell
i.e. the presence of fire and the amount of fuel in it. `rect' in both Map and
Simulation is a pair of points that in the first one indicates where on the
globe, in the LAEA\footnote{Projection Lambert azimuthal Equal-Area} Europe
\cite{laeae} coordinate system with reference system ETRS89\footnote{European
Terrestrial Reference System} \cite{etrs89}, the map is situated. The second one
indicates which subset of the map the simulation has been run on.

The use of the `unit' attribute in the Map entity indicates which multiple of
meters the points in `rect' are, this ensures that every possible coordinate is
in the correct multiple of digit, because the points in `rect' are stored as
integers.

Obviously the various arrays and rectangles have to be kept in check to avoid
inconsistent database state, using the ER semantic of Toni Mancini \cite{bd2}
let's express the non-trivial constrains on the data first in natural language
and then in fist order logic.

\begin{enumerate}
\item In Simulation the area of rect must be the same as the length of data,
\item the area of data in Result must be the same of the rect of its Simulation,
\item the rect of Map must contain the on of each Simulation on it
\item the seq attribute of Result must be a sequence of increasing numbers
starting from zero
\end{enumerate}

\begin{enumerate}
\item $\forall s,r,d.\textrm{Simulation}(s)
	\land \textrm{rect}(s,r)
	\land \textrm{data}(s,d)
	\rightarrow \textrm{equalArea}(r,d)$
\item $\forall s,rc,rs,d.\textrm{simulationResult}(s,rs) \allowbreak
	\land \textrm{Simulation}(s) \allowbreak
	\land \textrm{Result}(rs) \allowbreak
	\land \textrm{rect}(s,rc) \allowbreak
	\land \textrm{data}(rs,d) \allowbreak
	\rightarrow\textrm{equalArea}(rc,d)$
\item $\forall m,mr,s,sr. \textrm{Map}(m)
	\land \textrm{Simulation}(s) \allowbreak
	\land \textrm{rect}(s,sr) \allowbreak
	\land \textrm{mapSimulation}(m,s) \allowbreak
	\land \textrm{rect}(m,mr) \allowbreak
	\rightarrow \textrm{inside}(sr,mr)$
\item $\forall n,r.\textrm{Result}(r)
	\land\textrm{seq}(r,n)
	\rightarrow
	(n=0 \lor \exists r',n',s,s'.\textrm{Result}(r')
		\land r'\neq r
		\land \textrm{seq}(r,n')
		\land n'\neq n
		\land \textrm{sim}(r,s)
		\land \textrm{sim}(r',s')
		\land s'=s\rightarrow n'=n-1)$
\end{enumerate}

\subsection{Algorithm}

Given the description of the model the algorithm used for the simulation is
essentially map reduce \cite{sac}. Map in the sense that the input is evenly
distributed between the machine core and reduce in the sense that the halting
condition has to be checked by ORing together a piece of the work done by all
the cores. A pseudo-code description is shown in figure \ref{fig:code}. Instead
in figure \ref{fig:architecture} there is a simple architectural diagram of the
simulator program.

Something which is not quite clear from the pseudo-code is that the most
complicated part of the code is the checking of fire transmission by neighboring
cells. which is where the vast majority of the optimization efforts (excluding
the parallelization of the for loop) were made.

Also for brevity all the error checking/reporting while reading the input data
has been omitted but it required a good deal of effort to implement. But a brief
note on its implementation can be done here. To make file reading fast the
parsing and validation of the files is done in a single pass and the minimal
amount of allocation is done by the routine that reads the files from disk. This
has been archived via reuse of a resizable memory area (\texttt{realloc(3)}).

\begin{figure}
\centering
\begin{verse}
\textbf{until} simulation horizon has not been reached\\
\hspace{2em} \textbf{parallel for} each cell\\
\hspace{2em}\hspace{2em} \textbf{if} neighborhood can transmit fire to current cell \textbf{then}\\
\hspace{2em}\hspace{2em}\hspace{2em} update cell state and local termination condition\\
\hspace{2em}\hspace{2em} \textbf{else:}\\
\hspace{2em}\hspace{2em}\hspace{2em} copy old cell state\\
\hspace{2em} \textbf{reduce} all termination condition into one\\
\hspace{2em} \textbf{if} it is time to dump state \textbf{then}\\
\hspace{2em}\hspace{2em} dump state\\
\hspace{2em} \textbf{if} should exit because graceful halt signal has arrived \textbf{then}\\
\hspace{2em}\hspace{2em} exit\\
\hspace{2em} \textbf{if} should exit because termination condition \textbf{then}\\
\hspace{2em}\hspace{2em} exit
\end{verse}
\caption{Pseudo-code.}
\label{fig:code}
\end{figure}

\begin{figure}
\setlength{\unitlength}{1cm}
\newlength{\arrowlen}
\setlength{\arrowlen}{0.5\unitlength}
\newlength{\xcenter}
\setlength{\xcenter}{3.5\unitlength}
\newlength{\lateralarrowlength}
\setlength{\lateralarrowlength}{1\unitlength}
\centering

\begin{picture}(7,3)

\put(2.5,2){\fbox{CSV reader}}
\put(\xcenter,1.9){\vector(0,-1){\arrowlen}}
\put(2.5,1){\fbox{Simulation}}
\put(\xcenter,0.9){\vector(0,-1){\arrowlen}}
\put(3,0){\fbox{Exit}}

\put(0,1){Dump}
\put(1,1.1){\vector(1,0){\lateralarrowlength}}
\put(6,1.1){\vector(-1,0){\lateralarrowlength}}
\put(6,1){Signal}

\end{picture}
\vspace{0.6cm}
\caption{Architecture.}
\label{fig:architecture}
\end{figure}

\section{Implementation}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For the implementation various technologies have been considered but ultimately
discarded.

Modelica was considered initially as the implementation language but it has bad
support for this kind of simulation and on such a large scale, as said before.

Then for the data storage initially a simple flat file (a CSV \cite{csv} or
custom binary file for space reasons, in case space and reading speed were a
concern) was considered where all the data for the cells could have been stored
together with a coordinated but then it was ditched because of problem with
integration between various data sources and the handling of concurrent writes.

But the simulator inputs and outputs CSV files, to be more precise a subset of
this format was chosen: quoted numbers are not supported. This format was chosen
due to its simplicity. Another important factor was the wide support that this
format has.

Once C was chosen as the implementation language a possible approach for
speeding up the program execution was the use of SIMD instructions, because each
cell has 8 neighbors which if stored as \texttt{float} could neatly fit inside a
\texttt{YMM} register on x86. To avoid portability issues libraries like SLEEF
could have been used \cite{sleef}. This idea was ultimately ditched after a
simple algorithmic improvement i.e. not always simulating all the cells.

The rest of what is written in this section is ultimately what has been chosen
and used for the implementation.

The total number of lines of code (including comments) is roughly 1300. Not that
much considering what has been accomplished and the complete absence of external
libraries. Approximately a 950 of those are C code 250 SQL and the last 100
shell.

\subsection{SQL}

Firstly a DBMS had to be chosen for the implementation of the database schema.
The choice ended up being PostgreSQL thanks to its proven reliability (it has
more than 30 years of active development behind its back) and its support for
object-relational features of modern SQL, namely \texttt{ARRAY} data types.

The implementation of the schema for the database was divided in three parts.
First the creation of various \texttt{TYPE} and \texttt{DOMAIN} that modeled
the various data type needed for use in \texttt{ARRAY} so that they could be
easily stored and queryed together. Second the creation of the tables to hold the
various related data and to establish the relations among them. Third the
creation of the trigger to maintain the invariance stated in section
\ref{sec:schema}, across the various operations that modify the state of the
database.

The use of the \texttt{ARRAY} data type made really easy querying rectangular
shaped data (i.e. maps). For example let us say that we want to select the
sub-rectangle located between points $(x_0,y_0)$ and $(x_1,y_1)$, in our
rectangle, as a flat list of values, then the select part of our query would be
just this \texttt{(unnest(data[Y0:Y1][X0:X1])).*}, where we assume that our
rectangle is in the row called data.

Given the fact that we have to interact with geo-spatial data one may ask one
not use specific extensions like PostGIS. The reasons are simple, PostGIS
supports much more advanced operations that what we needed and sticking to
standard SQL ensures maximum portability of the schema and the queries (where
it is possible).

\subsection{C}

The simulator starts reading and validating three CSV files, for validation
meta-programming has been used through X-macros, to avoid excessive code
repetition. Eventual errors and communication to the user are all reported via
\texttt{syslog(3)}, that is the standardized logging mechanism by POSIX.

After this the code for handling software interrupts is set up. This was done
because a safe way of shutting down the program is needed in case of abrupt
changes to the meteorological data or the exogenous input. In this case the
simulation is terminated waiting for the last state dump to finish and then
restarted with the last valid state (or the best suited as starting conditions)
and the new data.

To avoid costly calls to \texttt{malloc(3)} all the memory allocations are done
before the start of the simulation and a double buffer technique is used to
recycle the memory of the last iteration.

Succeeding this the simulation is started, and after a certain number of
iterations (specified by the user) a snapshot of the state is taken to permit
both external programs to render the evolution of the fire and to enable recover
in case of the condition said before.

Various optimizations has been done for improving the performances of the
initial, trivial, implementation. The first was done by taking into
consideration the typical form of a forest fire, shown in figure \ref{fig:fire}.
It is clear that only a tiny part of the map is on fire at any point in time,
therefore we have to simulate only a fraction of the cell in the map, because a
cell can transmit fire iff it is it self on fire, as stated in function
\ref{eq:probtest}. Therefore if we see that a neighboring cell is not on fire
we can avoid doing calculations all together.

\begin{figure}
% https://www.copernicus.eu/en/copernicus-ems-rapid-mapping-activated-forest-fires-central-sweden
\centering
\includegraphics[scale=0.3]{fire.jpg}
\caption{Typical forest fire.}
\label{fig:fire}
\end{figure}

The other optimizations where more subtle, and spotted thanks to the profiler,
but still contributed to shave of some time from the simulation. The first was
archived moving the calculation of $\beta_{ij}$ from the start of the simulation
loop to the end of it, in a conditional branch this because on most cells no
calculation has to be done and reading $\mathcal{F}$ would bring in its entire
cache line, causing a probable miss. Instead in this way it is calculated only
when needed and when the cache line was already loaded due to previous mandatory
calculations.

The second optimization was done precalulating $d$ and the square root in $f_w$,
because both can assume only two values, and finally rewriting the sum of sine
and cosine in a form where a single call to the sine function is made.

Before talking about those optimizations a little note about precalculating
functions has to be made, in modern day usually the bottle neck is not the
number of instructions to execute but the amount of memory that one has to
access, therefore big tables of precalculated values are of no help.But the
ones considered in my scenario are all tiny, in fact they all fit in a single
cache line.

While $d$ is a relatively inexpensive value to calculate but it still contains a
call to libc and if the compiler is not smart enough could not be inlined, so
better to avoid this problem, the square root is a relatively expensive
operation especially in a hot loop like this but the really slow function were
the sine and cosine calculations, those certainly cannot be avoided but can be
improved removing the two function call to sine and cosine and transforming them
in a single one to sine. The procedure is shown in table
\ref{tab:simplifications}. As a side-note sine is also the same function called
in the Box-Muller transform to generate the normally distributed random numbers,
so that the sine code is always hot in the i-cache.

\begin{table}
\centering
\begin{tabular}{c c | c | c}
$\epsilon_1$ & $\epsilon_2$ & original equation & simplified equation\\
\hline
-1 & 1 & $-\cos(\alpha)+\sin(\alpha)$ & $-\sqrt{2}\sin(\frac{\pi}{4}-\alpha)$\\
0 & 1 & $\sin(\alpha)$ & $\sin(\alpha)$\\
1 & 1 & $\cos(\alpha) + \sin(\alpha)$ & $-\sqrt{2}\sin(\alpha+\frac{\pi}{4})$\\
-1 & 0 & $-\cos(\alpha)$ & $-\sin(\frac{\pi}{2}-\alpha)$\\
1 & 0 & $\cos(\alpha)$ & $\sin(\frac{\pi}{2}-\alpha)$\\
-1 & -1 & $-\cos(\alpha)-\sin(\alpha)$ & $-\sqrt{2}\sin(\alpha+\frac{\pi}{4})$\\
0 & -1 & $-\sin(\alpha)$ & $-\sin(\alpha)$\\
1 & -1 & $\cos(\alpha) + \sin(\alpha)$ & $\sqrt{2}\sin(\frac{\pi}{4}-\alpha)$\\
\end{tabular}
\caption{Simplifications}
\label{tab:simplifications}
\end{table}

\subsubsection{OpenMP}

The most effective optimization was the parallelization of the algorithm
together with the skip of cell that did not needed to be simulated. This
obviously because the algorithm is trivially parallelizable, due to the fact
that there is no need to communication between the thread, except for the one at
the end of the for loop. But even if the algorithm lends itself well to
parallelization some consideration had to be taken to avoid trivial performance
losses.

Because of this OpenMP allowed to easily and efficiently parallelize the main
loop of the simulator. The only \texttt{pragma} used was the one in figure
\ref{fig:pragma}. Now let's explain it, the first part \verb+#pragma omp parallel for+
just tells OpenMP to parallelize this \texttt{for} across the default number of
cores and equally divides the number of iterations to the number of default
cores.

The \texttt{collapse(2)} just fuses the two nested loops into one, this is done
to avoid problems in case of particularly short and wide simulation areas. In
this cases the work could not be rightly divided among the cores. And speaking
about work splitting among cores \texttt{schedule(static)} was chosen. This
basically tells the compiler to divide the iterations of the loop in a number of
chunks equal to the number of cores and assign one of those chunk to each core.
Because the amount of work that each core had to do was almost equal this should
pretty much be the optimal configuration. The other kinds of schedule offered by
OpenMP like \texttt{dynamic} and \texttt{guided} just added more overhead due to
the synchronization that they require to operate.

\verb+default(none)+ \verb+firstprivate(rng_state)+ \verb+shared(s,Gamma,d,sqrt)+
are used to specify the visibility of the variables outside the loop, the first
one just tell to not use any default, so that for every single variable we have
to specify the sharing policy, the second one gives a copy of the variable
\verb+rng_state+ to each core and initializes it to the same value in each of
them, the third just says that those variables are shared among threads.

Finally \verb+reduction(|: has_transmitted_fire)+ just tells that at the end of
the execution each thread all the private copies of \verb+has_transmitted_fire+
shall be ORed together. This is done to efficiently implement the halting
condition avoiding problems like lock contention or false sharing.

\begin{figure}
\centering
\footnotesize
\verb+#pragma omp parallel for collapse(2) default(none) firstprivate(rng_state)+
\verb+shared(s,Gamma,d,sqrt) reduction(|: has_transmitted_fire) schedule(static)+
\caption{OpenMP \texttt{pragma} used}
\label{fig:pragma}
\end{figure}

\subsection{Shell}

The POSIX shell \texttt{sh(1)}, together with its utilities, was used in the and
as the integration language between the two pieces of the simulator. It was used
especially for its omnipresence in UNIX like systems, and my familiarity with
it.

The most used command in the script was \texttt{psql(1)}. While it is not a
POSIX command it still comes bundled with PostgreSQL our database of choice, so
no additional dependencies are required. It allowed to easily mix SQL with shell
code, and thanks to its support of variables it allowed safe interpolation
between user supplied strings and the SQL code. Also the output generated by the
query could be easily formatted to make it easier to use in the rest of the
shell script.

\section{Experimental Results}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Now I am going to talk about the experimental results gathered during the
internship period. The primary experimental activity carried were software
testing and performance measuring.

\subsection{Goals}

The goals of the experiments done on the simulator software were first to show
the correct execution of the single parts and the integration between the
database part of the simulator and the part that executes the model worked
correctly. The second objective was to show the fulfillment of the performance
requirements established by my advisor, which were a maximum o 1$\mu$s of time
to process a single cell, which was largely respected.

\subsection{Setting}

The majority of the testing and development was done on a machine running mac OS
Big Sur with an Intel Core i7 6 core processor. But for ensuring the correct
execution in the Linux environment, where the program was supposed to run,
compilation and execution of workloads has also been done on Linux (and some
bugs have been discovered there exclusively).

On the software side of things two compilers have been used \texttt{clang(1)}
and \texttt{gcc(1)}, the profiler used was Apple's Instruments.app, the debugger
was \texttt{lldb(1)}. Both compiler supported various warnings and debugging
features namely sanitizers. And the C language standard library offered the
\texttt{assert(3)} macro that was extensively used throughout the code.

\subsection{Correctness}

Correctness of the various parts of the software has been shown with mostly hand
generated test cases, and manual testing. Automated testing like fuzzing has not
been used mostly becouse of my inexpirience with them. Also a unit-testig could
not be done in an effective way becouse of the continous change of requirements.

For the database schema testing various \texttt{INSERT}, \texttt{DELETE} and
\texttt{UPDATE} clauses have been tried to trigger all the various check of the
data. No bogus data was able to get in the database after the testing was done.

C is a notoriously error prone language to program in, this includes it's
integer (and float) conversion, manual memory management, undefined behavior and
pointer arithmetic. But tools can help a lot in producing good quality software,
most of which comes included with modern compilers.

For the execution part the majority of bugs where caught or reported via
warnings and the AddressSanitizer \cite{asan} feature of both \texttt{gcc(1)}
and \texttt{clang(1)}. During testing all the reported problems were solved and
no more were found. A special note has to be made about the few concurrency bugs
that were encountered all caught by setting \texttt{default(none)} in the OpenMP
\texttt{pragma}.

The only bugs that were not found by the previously mentioned tools in the model
executor, were logic ones related to the input validation. Wich some of them
were tricky to fix due to some poor choiches early in development.

The core part of the model executor was shown to be correct by inspection
because it is a relatively simple and straightforward function, thanks in part
to OpenMP who handled all the parallelism in a clean and transparent way, and
allowed to test sequential and parallel code correctness commenting out just a
line of code.

\subsection{Computational Performances}

The parallel code is much faster than the single core one as shown in table
\ref{tab:performance}, in the first column the number of updated cell is
expressed as the width times the height of the grid, times the number of
iterations. Then number of state dumps is displayed to show its effect on
performance. Then columns $T_S$ and $T_P$, shows serial and parallel time
respectively. Finally $S = T_S/T_P$ and $E = S/p$ shows the speedup and
efficiency, where $p$ is the number of cores (6 in this case).

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Updates} & \textbf{Dumps} & \textbf{$T_S$} & \textbf{$T_P$} & \textbf{$S$} & \textbf{$E$}\\
\hline
$10^6\times 100$ & 10 & 12.85s & 4.30s & 2.98 & 0.49\\
$10^6\times 100$ & 1 & 10.00s & 1.80s & 5.55 & 0.92\\
$10^6\times 1000$ & 10 & 98.64s & 17.35s & 5.68 & 0.94\\
$10^6\times 1000$ & 1 & 93.94s & 13.15s & 7.14 & 1.19\\
$10^6\times 10000$ & 1 & 929.67s & 147.09s & 6.32 & 1.05\\
\hline
\end{tabular}
\caption{Performance report.}
\label{tab:performance}
\end{table}

The size of the state for all the simulations was 8MB and the one for the cells
parameters was 20MB. The compiler options for the optimization were just
\texttt{-O3 -flto -DNDEBUG}. Taking the last row of table \ref{tab:performance}
as a reference we are able to process one cell in roughly $147.09s/10^{10}
\approx 14.7\textrm{ns}$, and we should always keep in mind that this is
starting from the worst possible starting conditions i.e. when all cells are on
fire.

To conclude the computational performance discussion I would like to remark the
amount of bytes/second processed, always taking the last row of table
\ref{tab:performance}. The state has been processed 10000, which times 8MB gives
us 80GB read and written in 929.67s or 86MB/s, with the same reasoning we get
215.1MB/s read from the parameters.


\section{Conclusion}

In the end a correct and performant implementation of the simulator was
delivered, definitely the hardest part of this internship did not came from the
development side but the software engineering one. Having to take a imprecise
model and transforming it into a real program was a real challenge. The
continuous update and changes made it really difficult to actually develop
something.

All the source code can be found on my GitHub account at the following URL
\url{https://github.com/l0r3m1psum/thesis}.

\subsection{Possible Improvements}

There are definitely many things to improve. First of all the error handling and
the logging are a little bit messy. Than the part of code that dumps the result
of simulation to disk could be made to execute on separate threads, to avoid
pauses while running the simulation, but then the software will not be anymore
allocation free in the main loop, so a carefully designed allocation strategy
would have to be developed. Something like a pool allocator should be good
enough knowing that that the simulation state has always the same size.

Another optimization could be tried like the one proposed in the Game
Programming Graphics Black Book (citation), that are especially suited for
sparse cellular automata simulation. Also the use of \texttt{PREFETCH}
instructions could help.

Also fuzzing could help find some lurking (unobvious) bugs.

\subsection{Future Work}

The execution part of the software could be rewritten as a library instead of
being a stand-alone program, because being written in C it is particularly
suited to be called by other languages (e.g. Java, Python etc\dots). To avoid
all the integration dance and concentrating directly in performant simulation.

A trivial version could be implemented on a GPU to see if the work saved by the
CPU implementation still makes it faster with respect to a GPU implementation.

\appendix

\section{Description of the satellite data}\label{sec:desc}

The values enumerated in the table \ref{tab:geo} are defined in the table
\ref{tab:forest}, \ref{tab:urbanization}, \ref{tab:water1}, \ref{tab:water2} and
\ref{tab:altimetry}.

\begin{table}[ht]
\centering
\begin{tabular}{|c|l|}
\hline
\textbf{Value} & \textbf{Class}\\
\hline
0 & Not forest\\
1 & Deciduous forest\\
2 & Coniferous forest\\
255 & External area\\
\hline
\end{tabular}
\caption{Forests}
\label{tab:forest}
\end{table}
%
\begin{table}[ht]
\centering
\begin{tabular}{|c|l|}
\hline
\textbf{Value} & \textbf{Class}\\
\hline
0 & Non waterproof zone\\
1 & Waterproof zone at 1\%\\
\vdots & \vdots\\
100 & Waterproof zone at 100\%\\
255 & External Area\\
\hline
\end{tabular}
\caption{Urbanization}
\label{tab:urbanization}
\end{table}
%
\begin{table}[ht]
\centering
\begin{tabular}{|c|l|}
\hline
\textbf{Value} & \textbf{Class}\\
\hline
0 & Torrent absence\\
1 & Torrent presence\\
\hline
\end{tabular}
\caption{Water 2}
\label{tab:water2}
\end{table}
%
\begin{table}[ht]
\centering
\begin{tabular}{|c|l|}
\hline
\textbf{Value} & \textbf{Class}\\
\hline
0 & Minimum height\\
\vdots & \vdots\\
4380 & Maximum height\\
\hline
\end{tabular}
\caption{Altimetry}
\label{tab:altimetry}
\end{table}
%
\begin{table}[ht]
\centering
\begin{tabular}{|c|l|}
\hline
\textbf{Value} & \textbf{Class}\\
\hline
0 & Dry soil\\
1 & Permanent water\\
2 & Temporary water\\
3 & Permanently wet\\
4 & Temporarily wet\\
253 & Sea cost water\\
255 & External area\\
\hline
\end{tabular}
\caption{Water 1}
\label{tab:water1}
\end{table}

\bibliographystyle{plain}
\bibliography{document} % TODO: cambiare il file in thesis.bib

\end{document}
